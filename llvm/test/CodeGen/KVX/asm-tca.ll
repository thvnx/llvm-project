; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O3 < %s | FileCheck %s
target triple = "kvx-kalray-cos"

define void @asm_tca(i8* %v, i64 %A) {
; CHECK-LABEL: asm_tca:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r2 = $r0
; CHECK-NEXT:    addd $r3 = $r1, 1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    lv $a0 = $r1[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv.s $a1 = $r3[$r2]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    #APP
; CHECK-NEXT:    copyv $a0 = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r2] = $a1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %add = add nsw i64 %A, 1
  %0 = tail call { <256 x i1>, <256 x i1> } asm sideeffect "lv $0 = $3[$2]\0A\09;;\0A\09lv.s $1 = $4[$2]\0A\09;;", "=w,=w,r,r,r,~{$r0}"(i8* %v, i64 %A, i64 %add)
  %asmresult = extractvalue { <256 x i1>, <256 x i1> } %0, 0
  %asmresult1 = extractvalue { <256 x i1>, <256 x i1> } %0, 1
  %1 = tail call <256 x i1> asm sideeffect "copyv $0 = $1\0A\09;;\0A\09sv 0[$3] = $2", "=w,w,w,r"(<256 x i1> %asmresult, <256 x i1> %asmresult1, i8* %v)
  ret void
}

define void @asm_clobber_vec_vec(i64 %A) {
; CHECK-LABEL: asm_clobber_vec_vec:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    #APP
; CHECK-NEXT:    copyv $a1 = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = tail call <256 x i1> asm sideeffect "copyv $0 = $1", "=w,w,~{$a0}"(<256 x i1> undef)
  ret void
}

define void @asm_clobber_vec_block(i64 %A) {
; CHECK-LABEL: asm_clobber_vec_block:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    #APP
; CHECK-NEXT:    copyv $a1 = $a0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = tail call <256 x i1> asm sideeffect "copyv $0 = $1", "=w,w,~{$a0.hi}"(<256 x i1> undef)
  ret void
}

define void @asm_clobber_wide_vec(<256 x i1>* nocapture readonly %a) {
; CHECK-LABEL: asm_clobber_wide_vec:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    lv $a2 = 0[$r0]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    copyv $a2 = $a2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, <256 x i1>* %a, align 32
  tail call void asm sideeffect "copyv $0 = $0", "w,~{$r0r1r2r3},~{$a0a1}"(<256 x i1> %0)
  ret void
}

define void @asm_clobber_multiple_quad(<256 x i1>* nocapture %c, <256 x i1>* nocapture %b) {
; CHECK-LABEL: asm_clobber_multiple_quad:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a4 = 0[$r4]
; CHECK-NEXT:    copyd $r5 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    copyv $a4 = $a5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyv $a5 = $a4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    sv 0[$r4] = $a4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 0[$r5] = $a5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, <256 x i1>* %c, align 32
  %1 = tail call { <256 x i1>, <256 x i1> } asm sideeffect "copyv $0 = $1\0A\09;;\0A\09copyv $1 = $0", "=w,=w,w,~{$r0r1r2r3},~{$a0a1a2a3}"(<256 x i1> %0)
  %asmresult = extractvalue { <256 x i1>, <256 x i1> } %1, 0
  %asmresult3 = extractvalue { <256 x i1>, <256 x i1> } %1, 1
  store <256 x i1> %asmresult, <256 x i1>* %c, align 32
  store <256 x i1> %asmresult3, <256 x i1>* %b, align 32
  ret void
}

define <256 x i1>* @asm_clobber_quad_matrix(<256 x i1>* readonly returned %a) {
; CHECK-LABEL: asm_clobber_quad_matrix:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a4 = 0[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    sv 0[$r3] = $a4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <256 x i1>, <256 x i1>* %a, align 32
  tail call void asm sideeffect "sv 0[$$r3] = $0", "w,~{$r0r1r2r3},~{$a0a1a2a3}"(<256 x i1> %0)
  ret <256 x i1>* %a
}

define void @use_wide_reg(<512 x i1>* nocapture %w, <256 x i1>* nocapture readonly %v) #1 {
; CHECK-LABEL: use_wide_reg:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r0
; CHECK-NEXT:    lv $a6 = 0[$r1]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a4 = 0[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a5 = 32[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    mma484bw $a4a5 = $a4a5, $a6, $a6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    sv 0[$r4] = $a4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r4] = $a5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <512 x i1>, <512 x i1>* %w, align 64
  %1 = load <256 x i1>, <256 x i1>* %v, align 32
  %2 = tail call <512 x i1> asm sideeffect "mma484bw $0 = $0, $1, $1", "=w,w,0,~{$r0r1r2r3},~{$a0a1a2a3}"(<256 x i1> %1, <512 x i1> %0)
  store <512 x i1> %2, <512 x i1>* %w, align 64
  ret void
}

define void @use_matrix_reg(<1024 x i1>* nocapture %x) #2 {
; CHECK-LABEL: use_matrix_reg:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    copyd $r4 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a4 = 0[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a5 = 32[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a6 = 64[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    lv $a7 = 96[$r4]
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #APP
; CHECK-NEXT:    mt44d $a4a5a6a7 = $a4a5a6a7
; CHECK-NEXT:    ;;
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    sv 0[$r4] = $a4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 32[$r4] = $a5
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 64[$r4] = $a6
; CHECK-NEXT:    ;;
; CHECK-NEXT:    sv 96[$r4] = $a7
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %0 = load <1024 x i1>, <1024 x i1>* %x, align 128
  %1 = tail call <1024 x i1> asm sideeffect "mt44d $0 = $0", "=w,0,~{$r0r1r2r3},~{$a0a1a2a3}"(<1024 x i1> %0)
  store <1024 x i1> %1, <1024 x i1>* %x, align 128
  ret void
}

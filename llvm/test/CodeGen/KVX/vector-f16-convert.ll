; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -O2 < %s | FileCheck %s

target triple = "kvx-kalray-cos"

define <2 x float> @expand2(<2 x half> %a) {
; CHECK-LABEL: expand2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fwidenlhwp $r0 = $r0
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fpext <2 x half> %a to <2 x float>
  ret <2 x float> %conv
}

define <4 x float> @expand4(<4 x half> %a) {
; CHECK-LABEL: expand4:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fwidenlhwp $r2 = $r0
; CHECK-NEXT:    fwidenmhwp $r3 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r0 = $r2
; CHECK-NEXT:    copyd $r1 = $r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fpext <4 x half> %a to <4 x float>
  ret <4 x float> %conv
}

; TODO: Support QuadReg in return CC should improve the generated code
; by avoiding the useless copyd instructions. These copyd instructions
; are the result of the new extract_subvector patterns introduced with
; this patch, fixing a worst behavior, using the stack as a way to
; convert the returning QuadReg into four SingleRegs.
define <8 x float> @expand8(<8 x half> %a) {
; CHECK-LABEL: expand8:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fwidenlhwp $r2 = $r1
; CHECK-NEXT:    fwidenlhwp $r4 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fwidenmhwp $r3 = $r1
; CHECK-NEXT:    fwidenmhwp $r5 = $r0
; CHECK-NEXT:    copyd $r0 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    copyd $r1 = $r5
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fpext <8 x half> %a to <8 x float>
  ret <8 x float> %conv
}

define <2 x half> @narrow2(<2 x float> %a) {
; CHECK-LABEL: narrow2:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    andw $r1 = $r0, 0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwhq $r0 = $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fptrunc <2 x float> %a to <2 x half>
  ret <2 x half> %conv
}

define <4 x half> @narrow4(<4 x float> %a) {
; CHECK-LABEL: narrow4:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fnarrowwhq $r0 = $r0r1
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fptrunc <4 x float> %a to <4 x half>
  ret <4 x half> %conv
}

define <8 x half> @narrow8(<8 x float> %a) {
; CHECK-LABEL: narrow8:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fnarrowwhq $r0 = $r0r1
; CHECK-NEXT:    fnarrowwhq $r1 = $r2r3
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fptrunc <8 x float> %a to <8 x half>
  ret <8 x half> %conv
}

; Sanity for v2f64 to v2f16 using scalar instructions.
define <2 x half> @narrow2d(<2 x double> %a) {
; CHECK-LABEL: narrow2d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fnarrowdw $r2 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowdw $r0 = $r0
; CHECK-NEXT:    fnarrowwh $r2 = $r2
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r2, 31, 16
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fptrunc <2 x double> %a to <2 x half>
  ret <2 x half> %conv
}

; Sanity for v4f64 to v4f16 using scalar instructions.
define <4 x half> @narrow4d(<4 x double> %a) {
; CHECK-LABEL: narrow4d:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    fnarrowdw $r4 = $r3
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowdw $r5 = $r2
; CHECK-NEXT:    fnarrowwh $r4 = $r4
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r5 = $r5
; CHECK-NEXT:    fnarrowdw $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r5 = $r4, 31, 16
; CHECK-NEXT:    fnarrowdw $r4 = $r1
; CHECK-NEXT:    ;;
; CHECK-NEXT:    fnarrowwh $r4 = $r4
; CHECK-NEXT:    fnarrowwh $r0 = $r0
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r4, 31, 16
; CHECK-NEXT:    ;;
; CHECK-NEXT:    insf $r0 = $r5, 63, 32
; CHECK-NEXT:    ret
; CHECK-NEXT:    ;;
entry:
  %conv = fptrunc <4 x double> %a to <4 x half>
  ret <4 x half> %conv
}
